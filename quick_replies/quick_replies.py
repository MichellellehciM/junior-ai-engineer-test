import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))  

def generate_quick_replies(chat_history, faq_list, product_list):
    """
    æ ¹æ“šå°è©±è¨˜éŒ„ç”Ÿæˆ Quick Replies å’Œ 5 å€‹ user å¯èƒ½æœƒæœ‰çš„å¾ŒçºŒå•é¡Œ
    :param chat_history:  User èˆ‡åŠ©ç†çš„å°è©±åˆ—è¡¨
    :param faq_list: å¸¸è¦‹å•é¡Œåˆ—è¡¨
    :param product_list: å•†å“æ¸…å–®
    :return: ä¸€å€‹åŒ…å« 5 å€‹å»ºè­°å›è¦†çš„åˆ—è¡¨
    """
    # å–å¾— user æœ€æ–°çš„å•é¡Œ
    last_user_message = None
    for message in reversed(chat_history):
        if message["role"] == "user":
            last_user_message = message["content"]
            break

    if not last_user_message:
        return ["(AIå®¢æœ): å¾ˆæŠ±æ­‰ï¼Œæˆ‘æ²’æœ‰æ”¶åˆ°æ‚¨çš„å•é¡Œï¼Œè«‹æ‚¨å†èªªä¸€æ¬¡å“¦ï¼"]

    # è¨­å®š Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å‹å¥½ä¸”å°ˆæ¥­çš„å®¢æœåŠ©ç†ï¼Œæ ¹æ“šä»¥ä¸‹çš„å°è©±è¨˜éŒ„ï¼Œç”Ÿæˆ Quick Replies å›æ‡‰ user çš„æœ€æ–°å•é¡Œï¼Œ
    ä¸¦ä¸”æ ¹æ“š User ç•¶å‰çš„å•é¡Œï¼Œé æ¸¬ä»–æ¥ä¸‹ä¾†å¯èƒ½æœƒå•çš„ 5 å€‹å•é¡Œï¼Œä¾†å¹«åŠ©ä»–ç²å¾—æ›´å¤šè³‡è¨Šã€‚

    å°è©±è¨˜éŒ„ï¼š
    {chat_history}

    ä»¥ä¸‹æ˜¯å¸¸è¦‹å•é¡Œï¼š
    {faq_list}

    ä»¥ä¸‹æ˜¯ç”¢å“æ¸…å–®ï¼š
    {product_list}


è«‹ä»¥ä»¥ä¸‹æ ¼å¼å›è¦†ï¼Œè®“å›æ‡‰æ›´æœ‰è¦ªå’ŒåŠ›ï¼Œå¯ä½¿ç”¨é©ç•¶çš„ emoji ä¾†è®“å°è©±æ›´ç”Ÿå‹•ï¼š

ğŸ˜Š **(AIå°å¹«æ‰‹)**: [é‡å°ç•¶å‰å•é¡Œçš„å›æ‡‰]ï¼Œå›ç­”å®Œå¾Œå¯ä»¥æƒ³è¾¦æ³•æŒ½ç•™å°æ–¹åœ¨ç¶²ç«™ä¸Šåœç•™çš„æ™‚é–“, ä¾‹å¦‚æˆ‘å¯ä»¥å¹«ä½ è©³ç´°ä»‹ç´¹ã€æœ‰éœ€è¦æˆ‘å†å¹«ä½ æŸ¥è©¢æ›´å¤šè³‡è¨Šå—ï¼Ÿ

ğŸ’¡ **(ä½ å¯èƒ½é‚„æƒ³å• 1)**: [ä½¿ç”¨è€…å¯èƒ½æœƒå•çš„å¾ŒçºŒå•é¡Œ]
ğŸ” **(ä½ å¯èƒ½é‚„æƒ³å• 2)**: [ä½¿ç”¨è€…å¯èƒ½æœƒå•çš„å¾ŒçºŒå•é¡Œ]
ğŸ“¦ **(ä½ å¯èƒ½é‚„æƒ³å• 3)**: [ä½¿ç”¨è€…å¯èƒ½æœƒå•çš„å¾ŒçºŒå•é¡Œ]
ğŸ›’ **(ä½ å¯èƒ½é‚„æƒ³å• 4)**: [ä½¿ç”¨è€…å¯èƒ½æœƒå•çš„å¾ŒçºŒå•é¡Œ]
ğŸ **(ä½ å¯èƒ½é‚„æƒ³å• 5)**: [ä½¿ç”¨è€…å¯èƒ½æœƒå•çš„å¾ŒçºŒå•é¡Œ]

ğŸ™‹â€â™€ï¸ **éœ€è¦çœŸäººå®¢æœå—ï¼Ÿ** é»é€™è£¡ğŸ‘‰ ã€çœŸäººå®¢æœã€‘ å°å¹«æ‰‹éš¨æ™‚ç‚ºæ‚¨æœå‹™ï¼âœ¨

    """

    try:
        # æ–°ç‰ˆ OpenAI API
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”å°ˆæ¥­çš„å®¢æœåŠ©ç†ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=250,
            temperature=0.7
        )
        # ç²å–å›è¦†å…§å®¹
        content = response.choices[0].message.content.strip()
        replies = content.split("\n")
        return [reply.lstrip("- ") for reply in replies if reply.strip()]
    except Exception as e:
        print(f"ç”Ÿæˆ Quick Replies æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return []


# é«’è³‡æ–™æ¸…æ´—
def clean_chat_history(chat_history):
    """
    æ¸…ç†å°è©±è¨˜éŒ„ï¼Œç§»é™¤é«’è³‡æ–™æˆ–ä¿®æ­£æ ¼å¼ä¸æ­£ç¢ºçš„é …ç›®
    :param chat_history: åŸå§‹å°è©±è¨˜éŒ„ (åˆ—è¡¨å½¢å¼)
    :return: æ¸…ç†å¾Œçš„å°è©±è¨˜éŒ„
    """
    cleaned_history = []
    for message in chat_history:
        # ç¢ºä¿æ¯å€‹é …ç›®éƒ½æœ‰ "role" å’Œ "content" ä¸¦ä¸”éç©º
        if isinstance(message, dict) and "role" in message and "content" in message:
            role = message["role"]
            content = message["content"]
            # æª¢æŸ¥ role æ˜¯å¦ç‚ºæœ‰æ•ˆå€¼
            if role in ["user", "assistant", "system"] and content:
                cleaned_history.append({"role": role, "content": content})
    return cleaned_history


# æ¸…ç†FAQå’Œproduct list
def clean_list(data_list):
    """
    æ¸…ç† FAQ æˆ–product listï¼Œç¢ºä¿å…§å®¹ç„¡ç©ºå€¼æˆ–ç„¡æ•ˆè³‡æ–™
    :param data_list: åŸå§‹çš„ FAQ æˆ–product list
    :return: ä¹¾æ·¨çš„åˆ—è¡¨
    """
    return [str(item).strip() for item in data_list if isinstance(item, str) and item.strip()]

